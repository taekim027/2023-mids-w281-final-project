{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbf836d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Path to the folder containing all the images\n",
    "path = \"/Users/michelle/Desktop/W281/final_project/rendered_256x256/256x256/sketch/tx_000100000000\"\n",
    "\n",
    "# List all the subdirectories (i.e., categories) in the main folder\n",
    "categories = os.listdir(path)\n",
    "categories = [x for x in categories if x != '.DS_Store']\n",
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e169d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 20s, sys: 14min 51s, total: 35min 11s\n",
      "Wall time: 16min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sift = cv2.SIFT_create(nfeatures=200, nOctaveLayers=4, contrastThreshold=0.04, edgeThreshold=15, sigma=1.0)\n",
    "\n",
    "# Define a list to store the descriptors of all the images\n",
    "descriptors = []\n",
    "\n",
    "# Define a list to store the corresponding labels of all the images\n",
    "labels = []\n",
    "\n",
    "# Loop through all the categories\n",
    "for i, category in enumerate(categories):\n",
    "    # Get the path to the category folder\n",
    "    category_path = os.path.join(path, category)\n",
    "    # List all the images in the category folder\n",
    "    images = os.listdir(category_path)\n",
    "    # Loop through all the images in the category folder\n",
    "    for image in images:\n",
    "        # Get the path to the image\n",
    "        image_path = os.path.join(category_path, image)\n",
    "        # Read the image\n",
    "        img = cv2.imread(image_path)\n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # Get the keypoints and descriptors using SIFT\n",
    "        kp, des = sift.detectAndCompute(gray, None)\n",
    "        # Reduce the descriptor size to 64 dimensions for speed\n",
    "        des = des[:, :64]\n",
    "        # Store the descriptors in the descriptors list\n",
    "        descriptors.append(des.flatten())\n",
    "        # Store the label i\n",
    "        labels.append(i)\n",
    "        \n",
    "        if len(descriptors) != len(labels):\n",
    "            print(i)\n",
    "            print(image_path)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8db4ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize vector length\n",
    "max_len = max([len(x) for x in descriptors])\n",
    "new_arr = [np.pad(x, (0, (max_len-len(x)))) for x in descriptors]\n",
    "#new_descriptors = [x[:min_length] for x in descriptors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f956e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(new_arr, labels, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0899950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD accuracy: 0.05020865072530967\n",
      "CPU times: user 14min 58s, sys: 24.9 s, total: 15min 23s\n",
      "Wall time: 4min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train an SGDClassifier to mimic the SVM model with mini-batch training\n",
    "sgd_model = SGDClassifier(loss='hinge', alpha=1/(30*len(X_train)), max_iter=1000, random_state=0)\n",
    "\n",
    "# Mini-batch training with batch size of 64\n",
    "batch_size = 64\n",
    "num_batches = len(X_train) // batch_size\n",
    "for i in range(num_batches):\n",
    "    X_batch = X_train[i*batch_size:(i+1)*batch_size]\n",
    "    Y_batch = Y_train[i*batch_size:(i+1)*batch_size]\n",
    "    sgd_model.partial_fit(X_batch, Y_batch, classes=np.unique(Y_train))\n",
    "\n",
    "sgd_preds = sgd_model.predict(X_test)\n",
    "sgd_acc = accuracy_score(Y_test, sgd_preds)\n",
    "print(f'SGD accuracy: {sgd_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48daa86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sgd_model.pkl', 'wb') as f:\n",
    "    pickle.dump(sgd_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eea382",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train an SVM with linear kernel\n",
    "svm_model = SVC(C=30, kernel='linear', random_state=0)\n",
    "svm_model.fit(X_train, Y_train)\n",
    "    \n",
    "# Evaluate the performance of SVM model\n",
    "svm_preds = svm_model.predict(X_test)\n",
    "svm_acc = accuracy_score(Y_test, svm_preds)\n",
    "print(f'SVM accuracy: {svm_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4945e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('svm_model.pkl', 'wb') as f:\n",
    "    pickle.dump(svm_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a5faec",
   "metadata": {},
   "source": [
    "### DONT RUN BELOW - KMEANS Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cb9a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmean_bow(all_descriptors, num_cluster):\n",
    "    \"\"\" run kmeans on the descriptors \"\"\"\n",
    "    bow_dict = []\n",
    "\n",
    "    kmeans = KMeans(n_clusters = num_cluster)\n",
    "    kmeans.fit(all_descriptors)\n",
    "\n",
    "    bow_dict = kmeans.cluster_centers_\n",
    "\n",
    "    return bow_dict\n",
    "\n",
    "\n",
    "def create_feature_bow(image_descriptors, BoW, num_cluster):\n",
    "\n",
    "    X_features = []\n",
    "\n",
    "    for i in range(len(image_descriptors)):\n",
    "        features = np.array([0] * num_cluster)\n",
    "\n",
    "        if image_descriptors[i] is not None:\n",
    "            distance = cdist(image_descriptors[i], BoW)\n",
    "            argmin = np.argmin(distance, axis = 1)\n",
    "\n",
    "            for j in argmin:\n",
    "                features[j] += 1\n",
    "        X_features.append(features)\n",
    "\n",
    "    return X_features\n",
    "\n",
    "all_descriptors = []\n",
    "for descriptor in descriptors:\n",
    "    if descriptor is not None:\n",
    "        for des in descriptor:\n",
    "            all_descriptors.append(des)\n",
    "            \n",
    "num_cluster = 20\n",
    "BoW = kmean_bow(all_descriptors, num_cluster)\n",
    "X_features = create_feature_bow(descriptors, BoW, num_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e245a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
