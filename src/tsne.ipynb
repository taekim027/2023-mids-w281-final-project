{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 12:19:43.043222: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-14 12:19:44.661221: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-04-14 12:19:47.644695: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-14 12:19:47.889630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-14 12:19:47.889717: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from typing import Iterable, Tuple, List\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print('Warning: without a GPU the training will take a lo:ng time...')\n",
    "\n",
    "IMAGE_SIZE = (256, 256, 3)\n",
    "NUM_CLASSES = 125\n",
    "SKETCH_ROOT = \"/home/sysung98/MIDS/W281/final_project/data/rendered_256x256/256x256/sketch\"\n",
    "tx_000100000000_fp = SKETCH_ROOT + '/tx_000100000000'\n",
    "\n",
    "categories = os.listdir(tx_000100000000_fp)\n",
    "categories = [x for x in categories if x != '.DS_Store']\n",
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_dataset(ratios: List[float], augmentations: List[str] = None, color_mode: str = 'rgb',\n",
    "                    seed: int = 1, batch_size: int = 32) -> List[tf.data.Dataset]:\n",
    "    '''\n",
    "    Get tensorflow dataset using generator to avoid RAM limitations\n",
    "    Splits into train, val, test from all provided augmentations \n",
    "    '''\n",
    "\n",
    "    # No augmentation by default\n",
    "    augmentations = augmentations or ['tx_000000000000']\n",
    "\n",
    "    assert sum(ratios) == 1 and len(ratios) == 3, 'Sum of 3 ratios must add to 1'\n",
    "\n",
    "    datasets: List[Tuple[tf.data.Dataset, tf.data.Dataset, tf.data.Dataset]] = []\n",
    "    for aug in augmentations:\n",
    "        print(f'Reading images from augmentation {aug}...')\n",
    "        train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "            directory = os.path.join(SKETCH_ROOT, aug),\n",
    "            image_size = IMAGE_SIZE[:2],\n",
    "            label_mode='categorical',\n",
    "            seed = seed,\n",
    "            color_mode = color_mode,\n",
    "            validation_split = (1 - ratios[0]),\n",
    "            subset = 'training',\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "            directory = os.path.join(SKETCH_ROOT, aug),\n",
    "            image_size = IMAGE_SIZE[:2],\n",
    "            label_mode='categorical',\n",
    "            seed = seed,\n",
    "            color_mode = 'rgb',\n",
    "            validation_split = (1 - ratios[0]),\n",
    "            subset = 'validation',\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        val_batch_count = int(tf.data.experimental.cardinality(val_ds))\n",
    "        test_ds = val_ds.take(int(val_batch_count * ratios[1]))\n",
    "        val_ds = val_ds.skip(int(val_batch_count * ratios[1]))\n",
    "\n",
    "        datasets.append([train_ds, val_ds, test_ds])\n",
    "    \n",
    "    combined = datasets.pop()\n",
    "    for train, val, test in datasets:\n",
    "        combined[0] = combined[0].concatenate(train)\n",
    "        combined[1] = combined[1].concatenate(val)\n",
    "        combined[2] = combined[2].concatenate(test)\n",
    "\n",
    "    if batch_size != None:\n",
    "        return [c.shuffle(batch_size) for c in combined]\n",
    "    else:\n",
    "        return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from augmentation tx_000100000000...\n",
      "Found 75481 files belonging to 125 classes.\n",
      "Using 60385 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 12:19:53.361153: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-14 12:19:53.361309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-14 12:19:53.361359: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-14 12:19:55.921204: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-14 12:19:55.921378: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-14 12:19:55.921393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-14 12:19:55.921442: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-14 12:19:55.921657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5897 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75481 files belonging to 125 classes.\n",
      "Using 15096 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds = get_image_dataset(\n",
    "    [0.8, 0.1, 0.1], \n",
    "    augmentations=['tx_000100000000'],\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 13:01:35.577755: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [60385]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-14 13:01:35.579211: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [60385]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1207, 65536)\n",
      "(1207,)\n"
     ]
    }
   ],
   "source": [
    "sample_train_ds = train_ds.take(tf.data.experimental.cardinality(train_ds) // 50)\n",
    "\n",
    "X = []\n",
    "true_y = []\n",
    "\n",
    "ct = 0\n",
    "for x, y in sample_train_ds.as_numpy_iterator():\n",
    "    true_y.append(np.argmax(y==1))\n",
    "    X.append(x.reshape((65536, )))\n",
    "\n",
    "X = np.array(X)\n",
    "true_y = np.array(true_y)\n",
    "\n",
    "print(X.shape)\n",
    "print(true_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing params: {'learning_rate': 5, 'perplexity': 50}\n",
      "silhouette_score: 0.36586230993270874\n",
      "num iters: 149\n",
      "\n",
      "Testing params: {'learning_rate': 5, 'perplexity': 75}\n",
      "silhouette_score: 0.35680365562438965\n",
      "num iters: 2399\n",
      "\n",
      "Testing params: {'learning_rate': 5, 'perplexity': 100}\n",
      "silhouette_score: 0.37026265263557434\n",
      "num iters: 149\n",
      "\n",
      "Testing params: {'learning_rate': 10, 'perplexity': 50}\n",
      "silhouette_score: 0.3790605068206787\n",
      "num iters: 2249\n",
      "\n",
      "Testing params: {'learning_rate': 10, 'perplexity': 75}\n",
      "silhouette_score: 0.3737393915653229\n",
      "num iters: 1599\n",
      "\n",
      "Testing params: {'learning_rate': 10, 'perplexity': 100}\n",
      "silhouette_score: 0.3897615969181061\n",
      "num iters: 2499\n",
      "\n",
      "Testing params: {'learning_rate': 20, 'perplexity': 50}\n",
      "silhouette_score: 0.36549368500709534\n",
      "num iters: 1499\n",
      "\n",
      "Testing params: {'learning_rate': 20, 'perplexity': 75}\n",
      "silhouette_score: 0.3703679144382477\n",
      "num iters: 2549\n",
      "\n",
      "Testing params: {'learning_rate': 20, 'perplexity': 100}\n",
      "silhouette_score: 0.3710382282733917\n",
      "num iters: 1749\n",
      "\n",
      "Testing params: {'learning_rate': 50, 'perplexity': 50}\n",
      "silhouette_score: 0.3657260537147522\n",
      "num iters: 2499\n",
      "\n",
      "Testing params: {'learning_rate': 50, 'perplexity': 75}\n",
      "silhouette_score: 0.37642261385917664\n",
      "num iters: 1399\n",
      "\n",
      "Testing params: {'learning_rate': 50, 'perplexity': 100}\n",
      "silhouette_score: 0.3700440526008606\n",
      "num iters: 1299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define function to calculate silhouette score\n",
    "def calc_silhouette(X_embedded, y, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init='auto', random_state=424)\n",
    "    labels = kmeans.fit_predict(X_embedded)\n",
    "    score = silhouette_score(X_embedded, labels)\n",
    "    return score\n",
    "\n",
    "param_grid = {\n",
    "    'perplexity': [50, 75, 100],\n",
    "    'learning_rate': [5, 10, 20, 50]\n",
    "}\n",
    "\n",
    "param_combinations = ParameterGrid(param_grid)\n",
    "\n",
    "for params in param_combinations:\n",
    "    print(f\"Testing params: {params}\")\n",
    "    tsne = TSNE(\n",
    "        perplexity=params['perplexity'], \n",
    "        learning_rate=params['learning_rate'],\n",
    "        n_iter=5000\n",
    "    )\n",
    "    X_embedded = tsne.fit_transform(X)\n",
    "\n",
    "    silhouette_scores = calc_silhouette(X_embedded, y, 125)\n",
    "\n",
    "    print(f'silhouette_score: {silhouette_scores}')\n",
    "    print(f'num iters: {tsne.n_iter_}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Y = tsne.fit_transform(\n",
    "#     X\n",
    "# )\n",
    "\n",
    "# plt.scatter(Y[:, 0], Y[:, 1], c=true_y)\n",
    "# plt.title('t-SNE visualization of data')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
