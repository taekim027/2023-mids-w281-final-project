{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 20:06:51.979074: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-14 20:06:52.713599: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-04-14 20:06:54.179979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-14 20:06:54.215979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-14 20:06:54.216046: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "from typing import Iterable, Tuple, List\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from utils import ImageDataset\n",
    "from typing import Callable, Tuple\n",
    "from tqdm import tqdm  \n",
    "from skimage.feature import hog\n",
    "from skimage.filters import sobel\n",
    "from skimage import exposure\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print('Warning: without a GPU the training will take a lo:ng time...')\n",
    "\n",
    "IMAGE_SIZE = (256, 256, 3)\n",
    "NUM_CLASSES = 125\n",
    "SKETCH_ROOT = \"/home/sysung98/MIDS/W281/final_project/data/rendered_256x256/256x256/sketch\"\n",
    "tx_000100000000_fp = SKETCH_ROOT + '/tx_000100000000'\n",
    "\n",
    "categories = os.listdir(tx_000100000000_fp)\n",
    "categories = [x for x in categories if x != '.DS_Store']\n",
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_dataset(ratios: List[float], augmentations: List[str] = None, color_mode: str = 'rgb',\n",
    "                    seed: int = 1, batch_size: int = 32) -> List[tf.data.Dataset]:\n",
    "    '''\n",
    "    Get tensorflow dataset using generator to avoid RAM limitations\n",
    "    Splits into train, val, test from all provided augmentations \n",
    "    '''\n",
    "\n",
    "    # No augmentation by default\n",
    "    augmentations = augmentations or ['tx_000000000000']\n",
    "\n",
    "    assert sum(ratios) == 1 and len(ratios) == 3, 'Sum of 3 ratios must add to 1'\n",
    "\n",
    "    datasets: List[Tuple[tf.data.Dataset, tf.data.Dataset, tf.data.Dataset]] = []\n",
    "    for aug in augmentations:\n",
    "        print(f'Reading images from augmentation {aug}...')\n",
    "        train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "            directory = os.path.join(SKETCH_ROOT, aug),\n",
    "            image_size = IMAGE_SIZE[:2],\n",
    "            label_mode='categorical',\n",
    "            seed = seed,\n",
    "            color_mode = color_mode,\n",
    "            validation_split = (1 - ratios[0]),\n",
    "            subset = 'training',\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "            directory = os.path.join(SKETCH_ROOT, aug),\n",
    "            image_size = IMAGE_SIZE[:2],\n",
    "            label_mode='categorical',\n",
    "            seed = seed,\n",
    "            color_mode = color_mode,\n",
    "            validation_split = (1 - ratios[0]),\n",
    "            subset = 'validation',\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        val_batch_count = int(tf.data.experimental.cardinality(val_ds))\n",
    "        test_ds = val_ds.take(int(val_batch_count * ratios[1]))\n",
    "        val_ds = val_ds.skip(int(val_batch_count * ratios[1]))\n",
    "\n",
    "        datasets.append([train_ds, val_ds, test_ds])\n",
    "    \n",
    "    combined = datasets.pop()\n",
    "    for train, val, test in datasets:\n",
    "        combined[0] = combined[0].concatenate(train)\n",
    "        combined[1] = combined[1].concatenate(val)\n",
    "        combined[2] = combined[2].concatenate(test)\n",
    "\n",
    "    if batch_size != None:\n",
    "        return [c.shuffle(batch_size) for c in combined]\n",
    "    else:\n",
    "        return combined\n",
    "\n",
    "def apply_feature_extraction(dataset: ImageDataset, func: Callable[[str], np.ndarray], name: str):\n",
    "    print('Applying feature extraction...')\n",
    "\n",
    "    for group in tqdm(dataset):\n",
    "        for sketch in group.sketches:\n",
    "            dest = sketch.filepath.parent.parent.parent / name / sketch.label / sketch.filepath.name\n",
    "            os.makedirs(dest.parent, exist_ok=True)\n",
    "            img = func(str(sketch.filepath))\n",
    "            img = cv2.convertScaleAbs(img, alpha=(255.0))\n",
    "            assert cv2.imwrite(str(dest), img)\n",
    "\n",
    "def hog_sobel(sketch_img_fp):\n",
    "    \"\"\" apply Histogram of Oriented Gradients (HOG) to sketch image \"\"\"\n",
    "    sketch_img = cv2.imread(sketch_img_fp)\n",
    "    gray = cv2.cvtColor(sketch_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    fd, hog_image = hog(\n",
    "        gray, \n",
    "        orientations = 8, \n",
    "        pixels_per_cell = (16, 16),\n",
    "        cells_per_block = (1, 1), \n",
    "        visualize = True\n",
    "    )\n",
    "    \n",
    "    min_value = np.min(hog_image)\n",
    "    max_value = np.max(hog_image)\n",
    "    hog_image = exposure.rescale_intensity(\n",
    "        hog_image, \n",
    "        in_range=(min_value, max_value), \n",
    "        out_range = (0, 1)\n",
    "    )\n",
    "    \n",
    "    return hog_image, sobel(gray)\n",
    "\n",
    "def hog_only(sketch_img_fp):\n",
    "    return hog_sobel(sketch_img_fp)[0]\n",
    "\n",
    "def transform_ds(ds, sample_rate=0):\n",
    "    if sample_rate != 0:\n",
    "        ds = ds.take(math.floor(tf.data.experimental.cardinality(train_ds) // sample_rate))\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for x, y in ds.as_numpy_iterator():\n",
    "        Y.append(np.argmax(y==1))\n",
    "        X.append(x.reshape((65536, )))\n",
    "\n",
    "    return (np.array(X), np.array(Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from augmentation tx_000100000000...\n",
      "Found 75481 files belonging to 125 classes.\n",
      "Using 60385 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 20:06:58.783512: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-14 20:06:58.783885: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-14 20:06:58.783982: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-14 20:06:59.844799: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-14 20:06:59.844977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-14 20:06:59.844990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-14 20:06:59.845086: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-14 20:06:59.845362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5897 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75481 files belonging to 125 classes.\n",
      "Using 15096 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 20:07:04.471243: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [60385]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-14 20:07:04.471481: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [60385]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-04-14 20:07:05.160055: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [15096]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-04-14 20:07:05.160299: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [15096]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds = get_image_dataset(\n",
    "    [0.8, 0.1, 0.1], \n",
    "    augmentations=['tx_000100000000'],\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size = None\n",
    ")\n",
    "\n",
    "train_X, train_Y = transform_ds(train_ds, 40)\n",
    "val_X, val_Y = transform_ds(val_ds, 40)\n",
    "\n",
    "# sample_train_ds = train_ds.take(tf.data.experimental.cardinality(train_ds) // 40)\n",
    "\n",
    "# X = []\n",
    "# true_y = []\n",
    "\n",
    "# ct = 0\n",
    "# for x, y in sample_train_ds.as_numpy_iterator():\n",
    "#     true_y.append(np.argmax(y==1))\n",
    "#     X.append(x.reshape((65536, )))\n",
    "\n",
    "# X = np.array(X)\n",
    "# true_y = np.array(true_y)\n",
    "\n",
    "# print(X.shape)\n",
    "# print(true_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing params: {'learning_rate': 5, 'perplexity': 50}\n",
      "silhouette_score: 0.3519884943962097\n",
      "num iters: 2849\n",
      "\n",
      "Testing params: {'learning_rate': 5, 'perplexity': 75}\n",
      "silhouette_score: 0.3603315055370331\n",
      "num iters: 2999\n",
      "\n",
      "Testing params: {'learning_rate': 5, 'perplexity': 100}\n",
      "silhouette_score: 0.36555424332618713\n",
      "num iters: 3949\n",
      "\n",
      "Testing params: {'learning_rate': 10, 'perplexity': 50}\n",
      "silhouette_score: 0.36207887530326843\n",
      "num iters: 2499\n",
      "\n",
      "Testing params: {'learning_rate': 10, 'perplexity': 75}\n",
      "silhouette_score: 0.36317941546440125\n",
      "num iters: 2349\n",
      "\n",
      "Testing params: {'learning_rate': 10, 'perplexity': 100}\n",
      "silhouette_score: 0.37487825751304626\n",
      "num iters: 1749\n",
      "\n",
      "Testing params: {'learning_rate': 20, 'perplexity': 50}\n",
      "silhouette_score: 0.3552260398864746\n",
      "num iters: 2649\n",
      "\n",
      "Testing params: {'learning_rate': 20, 'perplexity': 75}\n",
      "silhouette_score: 0.36230000853538513\n",
      "num iters: 2649\n",
      "\n",
      "Testing params: {'learning_rate': 20, 'perplexity': 100}\n",
      "silhouette_score: 0.3614940345287323\n",
      "num iters: 4049\n",
      "\n",
      "Testing params: {'learning_rate': 50, 'perplexity': 50}\n",
      "silhouette_score: 0.3558436930179596\n",
      "num iters: 2449\n",
      "\n",
      "Testing params: {'learning_rate': 50, 'perplexity': 75}\n",
      "silhouette_score: 0.3687871992588043\n",
      "num iters: 3049\n",
      "\n",
      "Testing params: {'learning_rate': 50, 'perplexity': 100}\n",
      "silhouette_score: 0.36290493607521057\n",
      "num iters: 1449\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define function to calculate silhouette score\n",
    "def calc_silhouette(X_embedded, y, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init='auto', random_state=424)\n",
    "    labels = kmeans.fit_predict(X_embedded)\n",
    "    score = silhouette_score(X_embedded, labels)\n",
    "    return score\n",
    "\n",
    "param_grid = {\n",
    "    'perplexity': [50, 75, 100],\n",
    "    'learning_rate': [5, 10, 20, 50]\n",
    "}\n",
    "\n",
    "param_combinations = ParameterGrid(param_grid)\n",
    "\n",
    "for params in param_combinations:\n",
    "    print(f\"Testing params: {params}\")\n",
    "    tsne = TSNE(\n",
    "        perplexity=params['perplexity'], \n",
    "        learning_rate=params['learning_rate'],\n",
    "        n_iter=5000\n",
    "    )\n",
    "\n",
    "    X_embedded = tsne.fit_transform(train_X)\n",
    "    # tsne.transform(transformed_ds)\n",
    "\n",
    "    silhouette_scores = calc_silhouette(X_embedded, train_Y, 125)\n",
    "\n",
    "    print(f'silhouette_score: {silhouette_scores}')\n",
    "    print(f'num iters: {tsne.n_iter_}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Y = tsne.fit_transform(\n",
    "#     X\n",
    "# )\n",
    "\n",
    "# plt.scatter(Y[:, 0], Y[:, 1], c=true_y)\n",
    "# plt.title('t-SNE visualization of data')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
