{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 13:26:15.400326: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from typing import Iterable, Tuple, List\n",
    "\n",
    "\n",
    "# If the following line throws an error, do `pip install -e ./` from the base repo dir\n",
    "from utils import ImageDataset\n",
    "\n",
    "# Change to match data filepath on local\n",
    "# base_fp = r'D:\\Documents\\MIDS\\W281\\2023-mids-w81-final-project-dataset\\256x256'\n",
    "base_fp = r'/Users/taehun.kim/mids/rendered_256x256/256x256'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loaded 12500 unique image IDs\n"
     ]
    }
   ],
   "source": [
    "# Load full dataset\n",
    "full_dataset = ImageDataset.from_directory(base_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = full_dataset.num_classes\n",
    "IMAGE_SIZE = full_dataset.image_size\n",
    "assert IMAGE_SIZE == full_dataset[0].photos[0].load().shape, 'Photos and sketches are not the same size'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split, need to split on ID\n",
    "train, valid, test = full_dataset.split([0.8, 0.1, 0.1])\n",
    "assert train.num_classes == valid.num_classes == test.num_classes\n",
    "\n",
    "# This approach not necessary as tf takes care of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75481 files belonging to 125 classes.\n",
      "Using 60385 files for training.\n",
      "Using 15096 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Train-valid-test split [0.8, 0.1, 0.1] using tensorflow generator to avoid RAM limitations\n",
    "no_aug_directory = '/Users/taehun.kim/mids/rendered_256x256/256x256/sketch/tx_000000000000'\n",
    "SEED = 1 # Must be same for train_ds and val_ds\n",
    "validation_split = 0.2\n",
    "\n",
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory =no_aug_directory,\n",
    "    image_size = IMAGE_SIZE[:2],\n",
    "    label_mode='categorical',\n",
    "    validation_split = validation_split,\n",
    "    subset = 'both',\n",
    "    seed = SEED,\n",
    "    color_mode = 'rgb'\n",
    ")\n",
    "\n",
    "val_batch_count = tf.data.experimental.cardinality(val_ds)\n",
    "test_ds = val_ds.take(val_batch_count // 2)\n",
    "val_ds = val_ds.skip(val_batch_count // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "pretrained_resnet = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    input_shape=IMAGE_SIZE,\n",
    "    pooling='avg',\n",
    "    classes=NUM_CLASSES,\n",
    ")\n",
    "pretrained_resnet.trainable = False\n",
    "\n",
    "layer = tf.keras.layers.Dense(1024, activation='relu')(pretrained_resnet.output)\n",
    "layer = tf.keras.layers.Dense(512, activation='relu')(layer)\n",
    "outputs = tf.keras.layers.Dense(len(train_ds.class_names), activation='softmax')(layer)\n",
    "model = tf.keras.Model(pretrained_resnet.input, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   5/1888 [..............................] - ETA: 5:57:34 - loss: 4.8739 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "# If below line isn't set, tf function decorator is thrown\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs,\n",
    "  callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=3,restore_best_weights=True)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcd43461cec7b7ccbf4c103209b89f37f7373e7d9282f855715f0d3c4b1c9bbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
